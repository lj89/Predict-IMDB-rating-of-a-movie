{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline multilayer perceptron (MLP) \n",
    "\n",
    "#### with 9 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw2= pd.read_csv('df_raw2_train.csv')\n",
    "df_raw2.drop(columns=['id'], inplace=True)\n",
    "df_imputed=df_raw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "director_name              float64\n",
       "num_critic_for_reviews     float64\n",
       "duration                   float64\n",
       "director_facebook_likes    float64\n",
       "actor_3_facebook_likes     float64\n",
       "                            ...   \n",
       "content_rating_PG-13         int64\n",
       "content_rating_Passed        int64\n",
       "content_rating_R             int64\n",
       "content_rating_Unrated       int64\n",
       "content_rating_X             int64\n",
       "Length: 672, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'imdb_score' in df_imputed:\n",
    "    y = df_imputed['imdb_score'].values # get the labels we want\n",
    "    del df_imputed['imdb_score'] # get rid of thelabel\n",
    "    X = df_imputed.values # use everything else to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1776)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf;print(\"tensorflow:\",tf.__version__)\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "\n",
    "tb = TensorBoard(log_dir=f\"logs\\\\{time()}\")\n",
    "tf.compat.v1.disable_eager_execution() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES=671\n",
    "weight_decay=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_171 (Dense)            (None, 300)               201600    \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_152 (Dropout)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_153 (Dropout)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_154 (Dropout)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 1,104,901\n",
      "Trainable params: 1,104,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2562 samples, validate on 641 samples\n",
      "Epoch 1/617\n",
      "2562/2562 [==============================] - 3s 1ms/sample - loss: 263508.9073 - mse: 691717210112.0000 - val_loss: 7298.8203 - val_mse: 123708744.0000\n",
      "Epoch 2/617\n",
      "2562/2562 [==============================] - 0s 104us/sample - loss: 12369.3862 - mse: 1199019008.0000 - val_loss: 2481.9210 - val_mse: 17173612.0000\n",
      "Epoch 3/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 4588.6252 - mse: 163679232.0000 - val_loss: 2414.3027 - val_mse: 13588156.0000\n",
      "Epoch 4/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 2739.0047 - mse: 48812676.0000 - val_loss: 521.0152 - val_mse: 819240.2500\n",
      "Epoch 5/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 1965.9677 - mse: 74681784.0000 - val_loss: 314.7142 - val_mse: 263420.8438\n",
      "Epoch 6/617\n",
      "2562/2562 [==============================] - 0s 93us/sample - loss: 1437.4041 - mse: 26524520.0000 - val_loss: 384.1096 - val_mse: 465823.0625\n",
      "Epoch 7/617\n",
      "2562/2562 [==============================] - 0s 94us/sample - loss: 1003.2755 - mse: 23590798.0000 - val_loss: 160.4949 - val_mse: 82024.7109\n",
      "Epoch 8/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 901.5879 - mse: 5797074.0000 - val_loss: 113.6401 - val_mse: 48301.5156\n",
      "Epoch 9/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 765.7250 - mse: 9165973.0000 - val_loss: 318.6727 - val_mse: 324395.0625\n",
      "Epoch 10/617\n",
      "2562/2562 [==============================] - 0s 94us/sample - loss: 693.9864 - mse: 5365177.5000 - val_loss: 113.3726 - val_mse: 54568.1445\n",
      "Epoch 11/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 575.9370 - mse: 1623517.2500 - val_loss: 100.5364 - val_mse: 35883.3711\n",
      "Epoch 12/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 520.3453 - mse: 2196212.2500 - val_loss: 99.8626 - val_mse: 27584.2363\n",
      "Epoch 13/617\n",
      "2562/2562 [==============================] - 0s 112us/sample - loss: 496.6601 - mse: 6450918.5000 - val_loss: 91.9450 - val_mse: 26627.4004\n",
      "Epoch 14/617\n",
      "2562/2562 [==============================] - 0s 108us/sample - loss: 412.0995 - mse: 979017.9375 - val_loss: 112.1250 - val_mse: 33695.3008\n",
      "Epoch 15/617\n",
      "2562/2562 [==============================] - 0s 107us/sample - loss: 386.3576 - mse: 1565481.0000 - val_loss: 103.6539 - val_mse: 35579.1953\n",
      "Epoch 16/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 341.3001 - mse: 599273.6875 - val_loss: 77.3401 - val_mse: 18905.7012\n",
      "Epoch 17/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 344.6672 - mse: 570955.2500 - val_loss: 68.0634 - val_mse: 16059.3027\n",
      "Epoch 18/617\n",
      "2562/2562 [==============================] - 0s 119us/sample - loss: 355.8385 - mse: 1090353.8750 - val_loss: 45.1398 - val_mse: 7741.6099\n",
      "Epoch 19/617\n",
      "2562/2562 [==============================] - 0s 112us/sample - loss: 407.3979 - mse: 5052385.5000 - val_loss: 54.4840 - val_mse: 8431.7881\n",
      "Epoch 20/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 313.0026 - mse: 558529.2500 - val_loss: 51.8227 - val_mse: 8906.6738\n",
      "Epoch 21/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 302.1620 - mse: 426157.2500 - val_loss: 48.0468 - val_mse: 8090.2207\n",
      "Epoch 22/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 288.2524 - mse: 723848.6250 - val_loss: 34.3509 - val_mse: 3983.6536\n",
      "Epoch 23/617\n",
      "2562/2562 [==============================] - 0s 115us/sample - loss: 270.6667 - mse: 789366.1875 - val_loss: 38.0902 - val_mse: 5382.6226\n",
      "Epoch 24/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 237.7970 - mse: 264393.0938 - val_loss: 44.4388 - val_mse: 5518.0864\n",
      "Epoch 25/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 240.7354 - mse: 648647.3750 - val_loss: 62.3263 - val_mse: 9416.6582\n",
      "Epoch 26/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 226.3525 - mse: 667391.3750 - val_loss: 27.8984 - val_mse: 2471.8975\n",
      "Epoch 27/617\n",
      "2562/2562 [==============================] - 0s 112us/sample - loss: 226.8150 - mse: 947636.6875 - val_loss: 48.4045 - val_mse: 9658.0215\n",
      "Epoch 28/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 227.5367 - mse: 666381.3750 - val_loss: 50.5766 - val_mse: 7981.4019\n",
      "Epoch 29/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 186.7077 - mse: 157241.3281 - val_loss: 23.6942 - val_mse: 2000.5267\n",
      "Epoch 30/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 221.0625 - mse: 1437495.0000 - val_loss: 43.1996 - val_mse: 4779.7842\n",
      "Epoch 31/617\n",
      "2562/2562 [==============================] - 0s 116us/sample - loss: 210.5969 - mse: 251330.1406 - val_loss: 51.6100 - val_mse: 13278.4199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 213.9038 - mse: 775086.4375 - val_loss: 39.8944 - val_mse: 8146.8550\n",
      "Epoch 33/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 193.5071 - mse: 514924.4062 - val_loss: 38.4286 - val_mse: 3572.2656\n",
      "Epoch 34/617\n",
      "2562/2562 [==============================] - 0s 112us/sample - loss: 173.7492 - mse: 234277.4688 - val_loss: 38.2463 - val_mse: 4095.5698\n",
      "Epoch 35/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 169.3591 - mse: 331748.9375 - val_loss: 37.1543 - val_mse: 4028.0679\n",
      "Epoch 36/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 165.8133 - mse: 300634.8438 - val_loss: 28.0536 - val_mse: 2608.8413\n",
      "Epoch 37/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 156.8474 - mse: 418766.9375 - val_loss: 20.5840 - val_mse: 1434.2042\n",
      "Epoch 38/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 145.7190 - mse: 183079.7500 - val_loss: 18.1323 - val_mse: 1085.0804\n",
      "Epoch 39/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 139.9878 - mse: 141897.5781 - val_loss: 22.6328 - val_mse: 3940.8127\n",
      "Epoch 40/617\n",
      "2562/2562 [==============================] - 0s 107us/sample - loss: 129.6694 - mse: 131524.3906 - val_loss: 22.9187 - val_mse: 1866.2289\n",
      "Epoch 41/617\n",
      "2562/2562 [==============================] - 0s 116us/sample - loss: 141.3645 - mse: 235688.1875 - val_loss: 21.1351 - val_mse: 2121.0195\n",
      "Epoch 42/617\n",
      "2562/2562 [==============================] - 0s 107us/sample - loss: 128.4342 - mse: 71374.2031 - val_loss: 17.0050 - val_mse: 1013.7614\n",
      "Epoch 43/617\n",
      "2562/2562 [==============================] - 0s 118us/sample - loss: 127.5069 - mse: 147330.6406 - val_loss: 18.7580 - val_mse: 1905.2393\n",
      "Epoch 44/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 128.4348 - mse: 323750.1562 - val_loss: 15.1123 - val_mse: 711.8651\n",
      "Epoch 45/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 130.0440 - mse: 598469.1875 - val_loss: 14.6409 - val_mse: 1153.5933\n",
      "Epoch 46/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 120.7088 - mse: 172261.5156 - val_loss: 18.7359 - val_mse: 1165.7871\n",
      "Epoch 47/617\n",
      "2562/2562 [==============================] - 0s 114us/sample - loss: 111.4393 - mse: 70558.0547 - val_loss: 22.0619 - val_mse: 1374.7115\n",
      "Epoch 48/617\n",
      "2562/2562 [==============================] - 0s 121us/sample - loss: 138.6708 - mse: 1282240.6250 - val_loss: 14.4155 - val_mse: 548.1215\n",
      "Epoch 49/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 114.7889 - mse: 150368.4688 - val_loss: 11.6723 - val_mse: 500.5784\n",
      "Epoch 50/617\n",
      "2562/2562 [==============================] - 0s 113us/sample - loss: 117.1126 - mse: 184632.7031 - val_loss: 19.1467 - val_mse: 1702.2749\n",
      "Epoch 51/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 119.9675 - mse: 181607.9375 - val_loss: 21.3130 - val_mse: 2338.1858\n",
      "Epoch 52/617\n",
      "2562/2562 [==============================] - 0s 114us/sample - loss: 110.1685 - mse: 131537.7500 - val_loss: 21.8106 - val_mse: 1443.7894\n",
      "Epoch 53/617\n",
      "2562/2562 [==============================] - 0s 115us/sample - loss: 101.5222 - mse: 63691.9609 - val_loss: 25.5566 - val_mse: 2157.8262\n",
      "Epoch 54/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 97.9105 - mse: 71689.8203 - val_loss: 18.1758 - val_mse: 928.0671\n",
      "Epoch 55/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 92.5608 - mse: 97499.5312 - val_loss: 11.2446 - val_mse: 321.3530\n",
      "Epoch 56/617\n",
      "2562/2562 [==============================] - 0s 117us/sample - loss: 85.6612 - mse: 60423.8633 - val_loss: 17.0153 - val_mse: 793.1696\n",
      "Epoch 57/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 89.8121 - mse: 102508.6875 - val_loss: 14.4554 - val_mse: 506.5853\n",
      "Epoch 58/617\n",
      "2562/2562 [==============================] - 0s 118us/sample - loss: 83.0958 - mse: 56966.8438 - val_loss: 18.5732 - val_mse: 1008.9336\n",
      "Epoch 59/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 92.9971 - mse: 238908.0000 - val_loss: 20.1020 - val_mse: 1378.6490\n",
      "Epoch 60/617\n",
      "2562/2562 [==============================] - 0s 121us/sample - loss: 85.8631 - mse: 108471.3594 - val_loss: 11.9082 - val_mse: 330.7799\n",
      "Epoch 61/617\n",
      "2562/2562 [==============================] - 0s 115us/sample - loss: 88.3757 - mse: 304053.8438 - val_loss: 12.2643 - val_mse: 392.3462\n",
      "Epoch 62/617\n",
      "2562/2562 [==============================] - 0s 116us/sample - loss: 74.8808 - mse: 95803.5938 - val_loss: 13.5551 - val_mse: 524.1209\n",
      "Epoch 63/617\n",
      "2562/2562 [==============================] - 0s 117us/sample - loss: 78.7930 - mse: 169310.3438 - val_loss: 10.8435 - val_mse: 256.1416\n",
      "Epoch 64/617\n",
      "2562/2562 [==============================] - 0s 123us/sample - loss: 68.4297 - mse: 33753.0000 - val_loss: 13.2683 - val_mse: 435.6471\n",
      "Epoch 65/617\n",
      "2562/2562 [==============================] - 0s 127us/sample - loss: 64.9631 - mse: 33586.8867 - val_loss: 12.9816 - val_mse: 361.5660\n",
      "Epoch 66/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 71.0134 - mse: 136803.8750 - val_loss: 18.0342 - val_mse: 875.0694\n",
      "Epoch 67/617\n",
      "2562/2562 [==============================] - 0s 122us/sample - loss: 65.9722 - mse: 33608.8477 - val_loss: 15.2936 - val_mse: 630.3430\n",
      "Epoch 68/617\n",
      "2562/2562 [==============================] - 0s 116us/sample - loss: 63.1319 - mse: 33385.0781 - val_loss: 11.7615 - val_mse: 311.8634\n",
      "Epoch 69/617\n",
      "2562/2562 [==============================] - 0s 122us/sample - loss: 63.8568 - mse: 76180.5000 - val_loss: 9.7168 - val_mse: 223.3613\n",
      "Epoch 70/617\n",
      "2562/2562 [==============================] - 0s 122us/sample - loss: 62.4429 - mse: 36568.4102 - val_loss: 14.2454 - val_mse: 500.0525\n",
      "Epoch 71/617\n",
      "2562/2562 [==============================] - 0s 121us/sample - loss: 61.1094 - mse: 48447.6328 - val_loss: 13.4930 - val_mse: 589.4068\n",
      "Epoch 72/617\n",
      "2562/2562 [==============================] - 0s 116us/sample - loss: 62.0548 - mse: 60273.8164 - val_loss: 13.3278 - val_mse: 487.3317\n",
      "Epoch 73/617\n",
      "2562/2562 [==============================] - 0s 128us/sample - loss: 65.0718 - mse: 126653.8359 - val_loss: 14.5459 - val_mse: 537.9432\n",
      "Epoch 74/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 59.0848 - mse: 46109.4570 - val_loss: 10.5886 - val_mse: 255.5798\n",
      "Epoch 75/617\n",
      "2562/2562 [==============================] - 0s 118us/sample - loss: 59.2340 - mse: 33139.9453 - val_loss: 12.8454 - val_mse: 739.9078\n",
      "Epoch 76/617\n",
      "2562/2562 [==============================] - 0s 130us/sample - loss: 61.1020 - mse: 102437.3125 - val_loss: 8.6367 - val_mse: 273.8463\n",
      "Epoch 77/617\n",
      "2562/2562 [==============================] - 0s 130us/sample - loss: 59.0386 - mse: 101705.5391 - val_loss: 8.0911 - val_mse: 145.2611\n",
      "Epoch 78/617\n",
      "2562/2562 [==============================] - 0s 129us/sample - loss: 50.7132 - mse: 37166.3398 - val_loss: 7.7626 - val_mse: 129.2780\n",
      "Epoch 79/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 46.5578 - mse: 20364.0645 - val_loss: 7.9460 - val_mse: 192.6965\n",
      "Epoch 80/617\n",
      "2562/2562 [==============================] - 0s 129us/sample - loss: 49.8517 - mse: 88568.1641 - val_loss: 5.1191 - val_mse: 64.0079\n",
      "Epoch 81/617\n",
      "2562/2562 [==============================] - 0s 127us/sample - loss: 41.7153 - mse: 15218.9072 - val_loss: 4.8365 - val_mse: 46.4553\n",
      "Epoch 82/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 43.1083 - mse: 32716.5488 - val_loss: 5.3788 - val_mse: 55.6556\n",
      "Epoch 83/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 39.4053 - mse: 9008.6865 - val_loss: 8.2086 - val_mse: 137.9338\n",
      "Epoch 84/617\n",
      "2562/2562 [==============================] - 0s 132us/sample - loss: 42.2906 - mse: 31521.9238 - val_loss: 9.8102 - val_mse: 190.6403\n",
      "Epoch 85/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 41.8130 - mse: 27875.4062 - val_loss: 8.0368 - val_mse: 118.9387\n",
      "Epoch 86/617\n",
      "2562/2562 [==============================] - 0s 128us/sample - loss: 45.7123 - mse: 75870.2812 - val_loss: 6.7940 - val_mse: 97.6475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/617\n",
      "2562/2562 [==============================] - 0s 128us/sample - loss: 43.6120 - mse: 63948.7891 - val_loss: 7.0057 - val_mse: 89.5310\n",
      "Epoch 88/617\n",
      "2562/2562 [==============================] - 0s 132us/sample - loss: 43.6903 - mse: 78900.9688 - val_loss: 8.0527 - val_mse: 107.4676\n",
      "Epoch 89/617\n",
      "2562/2562 [==============================] - 0s 127us/sample - loss: 38.9999 - mse: 17305.0664 - val_loss: 6.9019 - val_mse: 96.7360\n",
      "Epoch 90/617\n",
      "2562/2562 [==============================] - 0s 133us/sample - loss: 36.9622 - mse: 13536.7275 - val_loss: 6.4408 - val_mse: 144.4907\n",
      "Epoch 91/617\n",
      "2562/2562 [==============================] - 0s 136us/sample - loss: 38.5750 - mse: 23856.1133 - val_loss: 7.4398 - val_mse: 118.9281\n",
      "Epoch 92/617\n",
      "2562/2562 [==============================] - 0s 126us/sample - loss: 36.7105 - mse: 9246.8496 - val_loss: 8.4132 - val_mse: 133.9886\n",
      "Epoch 93/617\n",
      "2562/2562 [==============================] - 0s 137us/sample - loss: 43.9644 - mse: 51559.6758 - val_loss: 7.6375 - val_mse: 101.6918\n",
      "Epoch 94/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 38.3385 - mse: 14021.9219 - val_loss: 7.5044 - val_mse: 123.0300\n",
      "Epoch 95/617\n",
      "2562/2562 [==============================] - 0s 134us/sample - loss: 39.1793 - mse: 30359.8535 - val_loss: 6.9559 - val_mse: 130.9660\n",
      "Epoch 96/617\n",
      "2562/2562 [==============================] - 0s 136us/sample - loss: 42.8315 - mse: 81480.1406 - val_loss: 6.6380 - val_mse: 181.2374\n",
      "Epoch 97/617\n",
      "2562/2562 [==============================] - 0s 140us/sample - loss: 38.7971 - mse: 54424.7305 - val_loss: 5.8320 - val_mse: 169.6069\n",
      "Epoch 98/617\n",
      "2562/2562 [==============================] - 0s 136us/sample - loss: 40.7267 - mse: 24333.3438 - val_loss: 7.6663 - val_mse: 200.5158\n",
      "Epoch 99/617\n",
      "2562/2562 [==============================] - 0s 133us/sample - loss: 53.2265 - mse: 75102.3594 - val_loss: 7.9294 - val_mse: 383.0730\n",
      "Epoch 100/617\n",
      "2562/2562 [==============================] - 0s 140us/sample - loss: 64.5825 - mse: 118921.2578 - val_loss: 6.6149 - val_mse: 144.1381\n",
      "Epoch 101/617\n",
      "2562/2562 [==============================] - 0s 135us/sample - loss: 59.4881 - mse: 149961.4688 - val_loss: 12.1692 - val_mse: 276.4000\n",
      "Epoch 102/617\n",
      "2562/2562 [==============================] - 0s 139us/sample - loss: 49.9444 - mse: 51766.9727 - val_loss: 7.3934 - val_mse: 204.4946\n",
      "Epoch 103/617\n",
      "2562/2562 [==============================] - 0s 139us/sample - loss: 42.0806 - mse: 26816.5098 - val_loss: 6.7791 - val_mse: 198.5871\n",
      "Epoch 104/617\n",
      "2562/2562 [==============================] - 0s 138us/sample - loss: 46.9609 - mse: 255785.2969 - val_loss: 6.3697 - val_mse: 69.5657\n",
      "Epoch 105/617\n",
      "2562/2562 [==============================] - 0s 138us/sample - loss: 35.9765 - mse: 17031.8418 - val_loss: 6.4263 - val_mse: 76.7932\n",
      "Epoch 106/617\n",
      "2562/2562 [==============================] - 0s 140us/sample - loss: 30.5609 - mse: 6329.0405 - val_loss: 4.7135 - val_mse: 39.3086\n",
      "Epoch 107/617\n",
      "2562/2562 [==============================] - 0s 143us/sample - loss: 31.5254 - mse: 12735.3037 - val_loss: 5.9364 - val_mse: 54.8818\n",
      "Epoch 108/617\n",
      "2562/2562 [==============================] - 0s 144us/sample - loss: 34.4766 - mse: 40250.8398 - val_loss: 9.2921 - val_mse: 157.4467\n",
      "Epoch 109/617\n",
      "2562/2562 [==============================] - 0s 140us/sample - loss: 29.3015 - mse: 7119.0557 - val_loss: 8.4191 - val_mse: 162.6637\n",
      "Epoch 110/617\n",
      "2562/2562 [==============================] - 0s 138us/sample - loss: 29.7112 - mse: 15111.1084 - val_loss: 5.2911 - val_mse: 97.0205\n",
      "Epoch 111/617\n",
      "2562/2562 [==============================] - 0s 141us/sample - loss: 30.2902 - mse: 28417.6641 - val_loss: 4.7714 - val_mse: 80.4519\n",
      "Epoch 112/617\n",
      "2562/2562 [==============================] - 0s 139us/sample - loss: 28.2444 - mse: 14328.8467 - val_loss: 5.4188 - val_mse: 84.7148\n",
      "Epoch 113/617\n",
      "2562/2562 [==============================] - 0s 145us/sample - loss: 27.4186 - mse: 13056.1514 - val_loss: 5.8680 - val_mse: 84.2905\n",
      "Epoch 114/617\n",
      "2562/2562 [==============================] - 0s 145us/sample - loss: 23.6133 - mse: 2944.6514 - val_loss: 4.0874 - val_mse: 36.3470\n",
      "Epoch 115/617\n",
      "2562/2562 [==============================] - 0s 141us/sample - loss: 25.1743 - mse: 11973.3877 - val_loss: 5.0866 - val_mse: 41.3993\n",
      "Epoch 116/617\n",
      "2562/2562 [==============================] - 0s 142us/sample - loss: 22.7861 - mse: 5519.6899 - val_loss: 5.7356 - val_mse: 50.6116\n",
      "Epoch 117/617\n",
      "2562/2562 [==============================] - 0s 140us/sample - loss: 21.9621 - mse: 2584.1531 - val_loss: 6.4855 - val_mse: 65.3016\n",
      "Epoch 118/617\n",
      "2562/2562 [==============================] - 0s 149us/sample - loss: 21.8794 - mse: 5771.2197 - val_loss: 5.4174 - val_mse: 49.3045\n",
      "Epoch 119/617\n",
      "2562/2562 [==============================] - 0s 144us/sample - loss: 22.2264 - mse: 11380.3369 - val_loss: 3.5664 - val_mse: 20.7951\n",
      "Epoch 120/617\n",
      "2562/2562 [==============================] - 0s 141us/sample - loss: 21.5233 - mse: 12255.3242 - val_loss: 4.0860 - val_mse: 23.5728\n",
      "Epoch 121/617\n",
      "2562/2562 [==============================] - 0s 145us/sample - loss: 19.5214 - mse: 5868.9209 - val_loss: 4.6550 - val_mse: 31.9469\n",
      "Epoch 122/617\n",
      "2562/2562 [==============================] - 0s 155us/sample - loss: 17.9920 - mse: 13732.6914 - val_loss: 4.5744 - val_mse: 32.2124\n",
      "Epoch 123/617\n",
      "2562/2562 [==============================] - 0s 140us/sample - loss: 18.3840 - mse: 3625.8767 - val_loss: 3.3352 - val_mse: 17.7858\n",
      "Epoch 124/617\n",
      "2562/2562 [==============================] - 0s 145us/sample - loss: 19.5320 - mse: 14412.5947 - val_loss: 3.1702 - val_mse: 16.2740\n",
      "Epoch 125/617\n",
      "2562/2562 [==============================] - 0s 152us/sample - loss: 16.7672 - mse: 2874.6765 - val_loss: 3.2526 - val_mse: 18.2752\n",
      "Epoch 126/617\n",
      "2562/2562 [==============================] - 0s 151us/sample - loss: 24.1229 - mse: 177306.4375 - val_loss: 3.3275 - val_mse: 18.9092\n",
      "Epoch 127/617\n",
      "2562/2562 [==============================] - 0s 148us/sample - loss: 21.2385 - mse: 31417.1875 - val_loss: 4.4721 - val_mse: 32.6343\n",
      "Epoch 128/617\n",
      "2562/2562 [==============================] - 0s 146us/sample - loss: 15.9107 - mse: 2705.3706 - val_loss: 4.2037 - val_mse: 30.2861\n",
      "Epoch 129/617\n",
      "2562/2562 [==============================] - 0s 152us/sample - loss: 16.9341 - mse: 5836.6421 - val_loss: 3.8167 - val_mse: 27.0210\n",
      "Epoch 130/617\n",
      "2562/2562 [==============================] - 0s 151us/sample - loss: 16.6799 - mse: 19797.3848 - val_loss: 4.0057 - val_mse: 25.6783\n",
      "Epoch 131/617\n",
      "2562/2562 [==============================] - 0s 146us/sample - loss: 14.0278 - mse: 987.0635 - val_loss: 3.3663 - val_mse: 17.8925\n",
      "Epoch 132/617\n",
      "2562/2562 [==============================] - 0s 156us/sample - loss: 16.9530 - mse: 16131.5859 - val_loss: 3.5138 - val_mse: 19.9437\n",
      "Epoch 133/617\n",
      "2562/2562 [==============================] - 0s 153us/sample - loss: 16.1431 - mse: 15215.0645 - val_loss: 4.2368 - val_mse: 25.1738\n",
      "Epoch 134/617\n",
      "2562/2562 [==============================] - 0s 159us/sample - loss: 16.6092 - mse: 4642.7866 - val_loss: 5.0092 - val_mse: 37.0366\n",
      "Epoch 135/617\n",
      "2562/2562 [==============================] - 0s 163us/sample - loss: 14.2060 - mse: 912.5508 - val_loss: 3.7789 - val_mse: 28.9997\n",
      "Epoch 136/617\n",
      "2562/2562 [==============================] - 0s 147us/sample - loss: 14.5838 - mse: 5800.8428 - val_loss: 3.9975 - val_mse: 23.0469\n",
      "Epoch 137/617\n",
      "2562/2562 [==============================] - 0s 156us/sample - loss: 13.7414 - mse: 1611.7054 - val_loss: 3.8007 - val_mse: 22.4057\n",
      "Epoch 138/617\n",
      "2562/2562 [==============================] - 0s 154us/sample - loss: 12.9652 - mse: 2343.2690 - val_loss: 3.7033 - val_mse: 20.7328\n",
      "Epoch 139/617\n",
      "2562/2562 [==============================] - 0s 160us/sample - loss: 13.5179 - mse: 2687.0100 - val_loss: 4.7684 - val_mse: 31.5559\n",
      "Epoch 140/617\n",
      "2562/2562 [==============================] - 0s 160us/sample - loss: 13.4739 - mse: 2884.7271 - val_loss: 4.1199 - val_mse: 25.5874\n",
      "Epoch 141/617\n",
      "2562/2562 [==============================] - 0s 154us/sample - loss: 12.3424 - mse: 1353.9948 - val_loss: 3.5695 - val_mse: 19.3995\n",
      "Epoch 142/617\n",
      "2562/2562 [==============================] - 0s 169us/sample - loss: 13.0962 - mse: 3566.2192 - val_loss: 3.4561 - val_mse: 17.9934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/617\n",
      "2562/2562 [==============================] - 0s 181us/sample - loss: 12.2004 - mse: 1595.0552 - val_loss: 3.2957 - val_mse: 16.4297\n",
      "Epoch 144/617\n",
      "2562/2562 [==============================] - 1s 200us/sample - loss: 11.4848 - mse: 1236.3137 - val_loss: 3.4913 - val_mse: 17.9121\n",
      "Epoch 145/617\n",
      "2562/2562 [==============================] - 1s 212us/sample - loss: 11.2430 - mse: 1104.5210 - val_loss: 4.1614 - val_mse: 24.1585\n",
      "Epoch 146/617\n",
      "2562/2562 [==============================] - 1s 220us/sample - loss: 11.1606 - mse: 1314.1005 - val_loss: 3.4845 - val_mse: 19.3014\n",
      "Epoch 147/617\n",
      "2562/2562 [==============================] - 0s 194us/sample - loss: 10.9824 - mse: 2553.5862 - val_loss: 3.0955 - val_mse: 14.7668\n",
      "Epoch 148/617\n",
      "2562/2562 [==============================] - 0s 188us/sample - loss: 9.7799 - mse: 500.3250 - val_loss: 3.2530 - val_mse: 15.9590\n",
      "Epoch 149/617\n",
      "2562/2562 [==============================] - 0s 183us/sample - loss: 11.3865 - mse: 5548.7808 - val_loss: 3.5774 - val_mse: 18.1966\n",
      "Epoch 150/617\n",
      "2562/2562 [==============================] - 0s 185us/sample - loss: 10.4000 - mse: 1187.3109 - val_loss: 3.7695 - val_mse: 19.9348\n",
      "Epoch 151/617\n",
      "2562/2562 [==============================] - 0s 168us/sample - loss: 10.7492 - mse: 2004.9851 - val_loss: 3.3831 - val_mse: 16.6587\n",
      "Epoch 152/617\n",
      "2562/2562 [==============================] - 0s 177us/sample - loss: 9.3777 - mse: 600.0156 - val_loss: 3.4068 - val_mse: 16.8459\n",
      "Epoch 153/617\n",
      "2562/2562 [==============================] - 0s 172us/sample - loss: 8.6648 - mse: 578.4534 - val_loss: 3.8814 - val_mse: 20.7446\n",
      "Epoch 154/617\n",
      "2562/2562 [==============================] - 0s 191us/sample - loss: 9.2215 - mse: 563.3155 - val_loss: 3.9616 - val_mse: 21.4477\n",
      "Epoch 155/617\n",
      "2562/2562 [==============================] - 1s 195us/sample - loss: 8.8599 - mse: 751.4019 - val_loss: 3.0275 - val_mse: 14.0608\n",
      "Epoch 156/617\n",
      "2562/2562 [==============================] - 0s 188us/sample - loss: 8.9668 - mse: 990.3293 - val_loss: 2.7230 - val_mse: 12.2747\n",
      "Epoch 157/617\n",
      "2562/2562 [==============================] - 0s 175us/sample - loss: 8.5006 - mse: 1573.2159 - val_loss: 3.4544 - val_mse: 17.0744\n",
      "Epoch 158/617\n",
      "2562/2562 [==============================] - 0s 166us/sample - loss: 8.4791 - mse: 1163.8796 - val_loss: 3.4919 - val_mse: 17.3700\n",
      "Epoch 159/617\n",
      "2562/2562 [==============================] - 0s 169us/sample - loss: 8.5226 - mse: 1532.5563 - val_loss: 2.8367 - val_mse: 12.9166\n",
      "Epoch 160/617\n",
      "2562/2562 [==============================] - 0s 172us/sample - loss: 7.4952 - mse: 250.7440 - val_loss: 2.7344 - val_mse: 12.5459\n",
      "Epoch 161/617\n",
      "2562/2562 [==============================] - 0s 184us/sample - loss: 7.5654 - mse: 519.5152 - val_loss: 3.2455 - val_mse: 15.5121\n",
      "Epoch 162/617\n",
      "2562/2562 [==============================] - 0s 169us/sample - loss: 7.3525 - mse: 323.4660 - val_loss: 3.4970 - val_mse: 17.2938\n",
      "Epoch 163/617\n",
      "2562/2562 [==============================] - 0s 171us/sample - loss: 7.2072 - mse: 1006.0763 - val_loss: 2.9492 - val_mse: 13.4467\n",
      "Epoch 164/617\n",
      "2562/2562 [==============================] - 0s 166us/sample - loss: 7.1964 - mse: 686.5111 - val_loss: 2.7961 - val_mse: 12.3971\n",
      "Epoch 165/617\n",
      "2562/2562 [==============================] - 0s 166us/sample - loss: 7.1888 - mse: 526.1782 - val_loss: 2.9576 - val_mse: 13.3724\n",
      "Epoch 166/617\n",
      "2562/2562 [==============================] - 0s 169us/sample - loss: 6.9097 - mse: 445.1534 - val_loss: 2.8819 - val_mse: 12.8988\n",
      "Epoch 167/617\n",
      "2562/2562 [==============================] - 0s 170us/sample - loss: 6.4617 - mse: 238.8834 - val_loss: 3.4195 - val_mse: 16.8532\n",
      "Epoch 168/617\n",
      "2562/2562 [==============================] - 0s 169us/sample - loss: 7.0859 - mse: 314.7906 - val_loss: 3.6811 - val_mse: 19.5340\n",
      "Epoch 169/617\n",
      "2562/2562 [==============================] - 0s 182us/sample - loss: 7.7629 - mse: 1379.3875 - val_loss: 2.9346 - val_mse: 13.4477\n",
      "Epoch 170/617\n",
      "2562/2562 [==============================] - 0s 183us/sample - loss: 8.2703 - mse: 3822.0007 - val_loss: 3.3580 - val_mse: 16.4582\n",
      "Epoch 171/617\n",
      "2562/2562 [==============================] - 0s 180us/sample - loss: 6.6114 - mse: 321.1156 - val_loss: 2.8969 - val_mse: 12.9704\n",
      "Epoch 172/617\n",
      "2562/2562 [==============================] - 0s 174us/sample - loss: 6.4887 - mse: 430.8423 - val_loss: 2.5787 - val_mse: 10.9856\n",
      "Epoch 173/617\n",
      "2562/2562 [==============================] - 0s 175us/sample - loss: 6.6608 - mse: 711.0616 - val_loss: 2.7919 - val_mse: 12.1761\n",
      "Epoch 174/617\n",
      "2562/2562 [==============================] - 0s 186us/sample - loss: 6.7681 - mse: 477.5768 - val_loss: 3.3817 - val_mse: 16.3428\n",
      "Epoch 175/617\n",
      "2562/2562 [==============================] - 0s 180us/sample - loss: 6.2351 - mse: 612.1304 - val_loss: 2.8612 - val_mse: 12.6478\n",
      "Epoch 176/617\n",
      "2562/2562 [==============================] - 0s 173us/sample - loss: 7.0779 - mse: 3721.9226 - val_loss: 2.8807 - val_mse: 12.7783\n",
      "Epoch 177/617\n",
      "2562/2562 [==============================] - 0s 180us/sample - loss: 5.5626 - mse: 232.2588 - val_loss: 3.1791 - val_mse: 14.7605\n",
      "Epoch 178/617\n",
      "2562/2562 [==============================] - 0s 192us/sample - loss: 6.3552 - mse: 1104.2843 - val_loss: 2.5818 - val_mse: 10.6770\n",
      "Epoch 179/617\n",
      "2562/2562 [==============================] - 0s 187us/sample - loss: 6.2394 - mse: 1229.4952 - val_loss: 2.3196 - val_mse: 9.3290\n",
      "Epoch 180/617\n",
      "2562/2562 [==============================] - 0s 170us/sample - loss: 5.0992 - mse: 179.3962 - val_loss: 2.8043 - val_mse: 12.0558\n",
      "Epoch 181/617\n",
      "2562/2562 [==============================] - 0s 171us/sample - loss: 5.6755 - mse: 897.1947 - val_loss: 2.7029 - val_mse: 11.4346\n",
      "Epoch 182/617\n",
      "2562/2562 [==============================] - 0s 182us/sample - loss: 5.4073 - mse: 603.7922 - val_loss: 2.2893 - val_mse: 8.8770\n",
      "Epoch 183/617\n",
      "2562/2562 [==============================] - 0s 175us/sample - loss: 6.3658 - mse: 6316.2363 - val_loss: 2.0981 - val_mse: 7.9365\n",
      "Epoch 184/617\n",
      "2562/2562 [==============================] - 0s 174us/sample - loss: 4.5595 - mse: 103.2877 - val_loss: 2.8730 - val_mse: 12.4412\n",
      "Epoch 185/617\n",
      "2562/2562 [==============================] - 0s 168us/sample - loss: 4.8360 - mse: 177.2162 - val_loss: 2.4577 - val_mse: 9.8018\n",
      "Epoch 186/617\n",
      "2562/2562 [==============================] - 0s 172us/sample - loss: 4.4262 - mse: 123.6891 - val_loss: 2.2005 - val_mse: 8.4258\n",
      "Epoch 187/617\n",
      "2562/2562 [==============================] - 0s 174us/sample - loss: 4.5928 - mse: 163.6507 - val_loss: 2.0210 - val_mse: 7.5231\n",
      "Epoch 188/617\n",
      "2562/2562 [==============================] - 0s 165us/sample - loss: 4.7564 - mse: 764.9033 - val_loss: 2.0310 - val_mse: 7.6057\n",
      "Epoch 189/617\n",
      "2562/2562 [==============================] - 0s 168us/sample - loss: 4.5786 - mse: 181.0469 - val_loss: 1.7782 - val_mse: 6.1902\n",
      "Epoch 190/617\n",
      "2562/2562 [==============================] - 0s 178us/sample - loss: 4.1103 - mse: 235.2759 - val_loss: 1.5292 - val_mse: 4.9538\n",
      "Epoch 191/617\n",
      "2562/2562 [==============================] - 0s 179us/sample - loss: 4.1335 - mse: 281.9384 - val_loss: 1.4822 - val_mse: 4.7131\n",
      "Epoch 192/617\n",
      "2562/2562 [==============================] - 0s 171us/sample - loss: 4.1982 - mse: 160.4088 - val_loss: 1.4536 - val_mse: 4.7385\n",
      "Epoch 193/617\n",
      "2562/2562 [==============================] - 0s 169us/sample - loss: 3.7928 - mse: 196.8847 - val_loss: 1.2165 - val_mse: 3.7873\n",
      "Epoch 194/617\n",
      "2562/2562 [==============================] - 0s 170us/sample - loss: 3.1872 - mse: 77.2876 - val_loss: 1.1082 - val_mse: 3.3675\n",
      "Epoch 195/617\n",
      "2562/2562 [==============================] - 0s 169us/sample - loss: 3.8227 - mse: 331.8987 - val_loss: 0.9372 - val_mse: 2.7272\n",
      "Epoch 196/617\n",
      "2562/2562 [==============================] - 0s 178us/sample - loss: 3.2888 - mse: 90.3976 - val_loss: 0.7979 - val_mse: 2.2293\n",
      "Epoch 197/617\n",
      "2562/2562 [==============================] - 0s 173us/sample - loss: 3.4809 - mse: 249.8359 - val_loss: 0.6385 - val_mse: 1.7002\n",
      "Epoch 198/617\n",
      "2562/2562 [==============================] - 0s 173us/sample - loss: 8.2144 - mse: 59187.2734 - val_loss: 0.5752 - val_mse: 1.5077\n",
      "Epoch 199/617\n",
      "2562/2562 [==============================] - 0s 166us/sample - loss: 3.1635 - mse: 645.1965 - val_loss: 0.5103 - val_mse: 1.3225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/617\n",
      "2562/2562 [==============================] - 0s 177us/sample - loss: 3.4362 - mse: 516.0759 - val_loss: 0.4667 - val_mse: 1.1625\n",
      "Epoch 201/617\n",
      "2562/2562 [==============================] - 0s 189us/sample - loss: 4.8618 - mse: 8103.4902 - val_loss: 0.4581 - val_mse: 1.1505\n",
      "Epoch 202/617\n",
      "2562/2562 [==============================] - 0s 185us/sample - loss: 2.7374 - mse: 104.5317 - val_loss: 0.4557 - val_mse: 1.1559\n",
      "Epoch 203/617\n",
      "2562/2562 [==============================] - 0s 178us/sample - loss: 3.0620 - mse: 600.2720 - val_loss: 0.4576 - val_mse: 1.1713\n",
      "Epoch 204/617\n",
      "2562/2562 [==============================] - 0s 190us/sample - loss: 2.1878 - mse: 58.0098 - val_loss: 0.4610 - val_mse: 1.1884\n",
      "Epoch 205/617\n",
      "2562/2562 [==============================] - 0s 175us/sample - loss: 3.6243 - mse: 4956.2676 - val_loss: 0.4641 - val_mse: 1.2021\n",
      "Epoch 206/617\n",
      "2562/2562 [==============================] - 0s 165us/sample - loss: 2.2629 - mse: 149.9777 - val_loss: 0.4668 - val_mse: 1.2136\n",
      "Epoch 207/617\n",
      "2562/2562 [==============================] - 0s 171us/sample - loss: 3.5438 - mse: 2080.1638 - val_loss: 0.4673 - val_mse: 1.2156\n",
      "Epoch 208/617\n",
      "2562/2562 [==============================] - 0s 175us/sample - loss: 2.3200 - mse: 204.0748 - val_loss: 0.4680 - val_mse: 1.2182\n",
      "Epoch 209/617\n",
      "2562/2562 [==============================] - 0s 190us/sample - loss: 2.3056 - mse: 228.0353 - val_loss: 0.4678 - val_mse: 1.2174\n",
      "Epoch 210/617\n",
      "2562/2562 [==============================] - 0s 174us/sample - loss: 1.7596 - mse: 32.8292 - val_loss: 0.4667 - val_mse: 1.2131\n",
      "Epoch 211/617\n",
      "2562/2562 [==============================] - 0s 173us/sample - loss: 1.9144 - mse: 42.4064 - val_loss: 0.4660 - val_mse: 1.2103\n",
      "Epoch 212/617\n",
      "2562/2562 [==============================] - 0s 171us/sample - loss: 1.9650 - mse: 134.0121 - val_loss: 0.4656 - val_mse: 1.2085\n",
      "Epoch 213/617\n",
      "2562/2562 [==============================] - 0s 160us/sample - loss: 1.7101 - mse: 36.0937 - val_loss: 0.4653 - val_mse: 1.2072\n",
      "Epoch 214/617\n",
      "2562/2562 [==============================] - 0s 158us/sample - loss: 1.5856 - mse: 36.1465 - val_loss: 0.4646 - val_mse: 1.2042\n",
      "Epoch 215/617\n",
      "2562/2562 [==============================] - 0s 149us/sample - loss: 1.9794 - mse: 632.3887 - val_loss: 0.4636 - val_mse: 1.2002\n",
      "Epoch 216/617\n",
      "2562/2562 [==============================] - 0s 152us/sample - loss: 1.8971 - mse: 308.0044 - val_loss: 0.4621 - val_mse: 1.1934\n",
      "Epoch 217/617\n",
      "2562/2562 [==============================] - 0s 159us/sample - loss: 1.5910 - mse: 34.4840 - val_loss: 0.4605 - val_mse: 1.1862\n",
      "Epoch 218/617\n",
      "2562/2562 [==============================] - 0s 154us/sample - loss: 1.9355 - mse: 263.3066 - val_loss: 0.4593 - val_mse: 1.1804\n",
      "Epoch 219/617\n",
      "2562/2562 [==============================] - 0s 168us/sample - loss: 1.4932 - mse: 39.2195 - val_loss: 0.4582 - val_mse: 1.1747\n",
      "Epoch 220/617\n",
      "2562/2562 [==============================] - 0s 155us/sample - loss: 1.7361 - mse: 202.3145 - val_loss: 0.4573 - val_mse: 1.1695\n",
      "Epoch 221/617\n",
      "2562/2562 [==============================] - 0s 161us/sample - loss: 1.3937 - mse: 29.7194 - val_loss: 0.4567 - val_mse: 1.1658\n",
      "Epoch 222/617\n",
      "2562/2562 [==============================] - 0s 156us/sample - loss: 1.7458 - mse: 77.2223 - val_loss: 0.4563 - val_mse: 1.1631\n",
      "Epoch 223/617\n",
      "2562/2562 [==============================] - 0s 153us/sample - loss: 1.2824 - mse: 15.1278 - val_loss: 0.4564 - val_mse: 1.1635\n",
      "Epoch 224/617\n",
      "2562/2562 [==============================] - 0s 156us/sample - loss: 1.5852 - mse: 70.7356 - val_loss: 0.4567 - val_mse: 1.1661\n",
      "Epoch 225/617\n",
      "2562/2562 [==============================] - 0s 149us/sample - loss: 1.4456 - mse: 36.7050 - val_loss: 0.4574 - val_mse: 1.1702\n",
      "Epoch 226/617\n",
      "2562/2562 [==============================] - 0s 153us/sample - loss: 1.5021 - mse: 72.4154 - val_loss: 0.4578 - val_mse: 1.1728\n",
      "Epoch 227/617\n",
      "2562/2562 [==============================] - 0s 148us/sample - loss: 1.5850 - mse: 145.6767 - val_loss: 0.4578 - val_mse: 1.1726\n",
      "Epoch 228/617\n",
      "2562/2562 [==============================] - 0s 154us/sample - loss: 1.2739 - mse: 27.8428 - val_loss: 0.4573 - val_mse: 1.1700\n",
      "Epoch 229/617\n",
      "2562/2562 [==============================] - 0s 149us/sample - loss: 1.0691 - mse: 16.5375 - val_loss: 0.4567 - val_mse: 1.1659\n",
      "Epoch 230/617\n",
      "2562/2562 [==============================] - 0s 145us/sample - loss: 1.3002 - mse: 38.0388 - val_loss: 0.4566 - val_mse: 1.1651\n",
      "Epoch 231/617\n",
      "2562/2562 [==============================] - 0s 149us/sample - loss: 1.1022 - mse: 24.1119 - val_loss: 0.4565 - val_mse: 1.1648\n",
      "Epoch 232/617\n",
      "2562/2562 [==============================] - 0s 155us/sample - loss: 1.3681 - mse: 82.9705 - val_loss: 0.4561 - val_mse: 1.1617\n",
      "Epoch 233/617\n",
      "2562/2562 [==============================] - 0s 147us/sample - loss: 1.1576 - mse: 20.9338 - val_loss: 0.4560 - val_mse: 1.1605\n",
      "Epoch 234/617\n",
      "2562/2562 [==============================] - 0s 143us/sample - loss: 1.5742 - mse: 123.0316 - val_loss: 0.4559 - val_mse: 1.1600\n",
      "Epoch 235/617\n",
      "2562/2562 [==============================] - 0s 147us/sample - loss: 1.2800 - mse: 45.1965 - val_loss: 0.4560 - val_mse: 1.1605\n",
      "Epoch 236/617\n",
      "2562/2562 [==============================] - 0s 148us/sample - loss: 1.0941 - mse: 37.7840 - val_loss: 0.4561 - val_mse: 1.1611\n",
      "Epoch 237/617\n",
      "2562/2562 [==============================] - 0s 147us/sample - loss: 0.9464 - mse: 10.1561 - val_loss: 0.4560 - val_mse: 1.1606\n",
      "Epoch 238/617\n",
      "2562/2562 [==============================] - 0s 146us/sample - loss: 1.1383 - mse: 42.7599 - val_loss: 0.4558 - val_mse: 1.1587\n",
      "Epoch 239/617\n",
      "2562/2562 [==============================] - 0s 146us/sample - loss: 0.9504 - mse: 12.8738 - val_loss: 0.4557 - val_mse: 1.1568\n",
      "Epoch 240/617\n",
      "2562/2562 [==============================] - 0s 144us/sample - loss: 0.9891 - mse: 13.7580 - val_loss: 0.4557 - val_mse: 1.1561\n",
      "Epoch 241/617\n",
      "2562/2562 [==============================] - 0s 140us/sample - loss: 1.0929 - mse: 28.0474 - val_loss: 0.4557 - val_mse: 1.1560\n",
      "Epoch 242/617\n",
      "2562/2562 [==============================] - 0s 140us/sample - loss: 0.8935 - mse: 11.0946 - val_loss: 0.4557 - val_mse: 1.1564\n",
      "Epoch 243/617\n",
      "2562/2562 [==============================] - 0s 141us/sample - loss: 0.9688 - mse: 22.9136 - val_loss: 0.4557 - val_mse: 1.1566\n",
      "Epoch 244/617\n",
      "2562/2562 [==============================] - 0s 152us/sample - loss: 1.0867 - mse: 39.4795 - val_loss: 0.4557 - val_mse: 1.1560\n",
      "Epoch 245/617\n",
      "2562/2562 [==============================] - 0s 153us/sample - loss: 1.0438 - mse: 21.0770 - val_loss: 0.4557 - val_mse: 1.1550\n",
      "Epoch 246/617\n",
      "2562/2562 [==============================] - 0s 152us/sample - loss: 0.7852 - mse: 7.6608 - val_loss: 0.4557 - val_mse: 1.1544\n",
      "Epoch 247/617\n",
      "2562/2562 [==============================] - 0s 141us/sample - loss: 0.7834 - mse: 10.0879 - val_loss: 0.4557 - val_mse: 1.1537\n",
      "Epoch 248/617\n",
      "2562/2562 [==============================] - 0s 141us/sample - loss: 0.8809 - mse: 22.2124 - val_loss: 0.4558 - val_mse: 1.1534\n",
      "Epoch 249/617\n",
      "2562/2562 [==============================] - 0s 138us/sample - loss: 0.8774 - mse: 12.7094 - val_loss: 0.4557 - val_mse: 1.1535\n",
      "Epoch 250/617\n",
      "2562/2562 [==============================] - 0s 140us/sample - loss: 1.3751 - mse: 718.6913 - val_loss: 0.4557 - val_mse: 1.1538\n",
      "Epoch 251/617\n",
      "2562/2562 [==============================] - 0s 141us/sample - loss: 0.9070 - mse: 13.5058 - val_loss: 0.4557 - val_mse: 1.1543\n",
      "Epoch 252/617\n",
      "2562/2562 [==============================] - 0s 139us/sample - loss: 0.9949 - mse: 42.3685 - val_loss: 0.4557 - val_mse: 1.1539\n",
      "Epoch 253/617\n",
      "2562/2562 [==============================] - 0s 139us/sample - loss: 0.8495 - mse: 12.4073 - val_loss: 0.4558 - val_mse: 1.1528\n",
      "Epoch 254/617\n",
      "2562/2562 [==============================] - 0s 142us/sample - loss: 0.8555 - mse: 17.0044 - val_loss: 0.4559 - val_mse: 1.1524\n",
      "Epoch 255/617\n",
      "2562/2562 [==============================] - 0s 155us/sample - loss: 0.8548 - mse: 21.2901 - val_loss: 0.4559 - val_mse: 1.1526\n",
      "Epoch 256/617\n",
      "2562/2562 [==============================] - 0s 147us/sample - loss: 0.7714 - mse: 7.7543 - val_loss: 0.4558 - val_mse: 1.1530\n",
      "Epoch 257/617\n",
      "2562/2562 [==============================] - 0s 139us/sample - loss: 0.8768 - mse: 12.6057 - val_loss: 0.4558 - val_mse: 1.1528\n",
      "Epoch 258/617\n",
      "2562/2562 [==============================] - 0s 134us/sample - loss: 0.7542 - mse: 10.4599 - val_loss: 0.4559 - val_mse: 1.1522\n",
      "Epoch 259/617\n",
      "2562/2562 [==============================] - 0s 133us/sample - loss: 0.8736 - mse: 34.0808 - val_loss: 0.4559 - val_mse: 1.1522\n",
      "Epoch 260/617\n",
      "2562/2562 [==============================] - 0s 136us/sample - loss: 0.7558 - mse: 7.9580 - val_loss: 0.4558 - val_mse: 1.1529\n",
      "Epoch 261/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 0.7323 - mse: 14.2932 - val_loss: 0.4557 - val_mse: 1.1536\n",
      "Epoch 262/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 0.6930 - mse: 5.5353 - val_loss: 0.4558 - val_mse: 1.1530\n",
      "Epoch 263/617\n",
      "2562/2562 [==============================] - 0s 138us/sample - loss: 0.7755 - mse: 10.1018 - val_loss: 0.4559 - val_mse: 1.1524\n",
      "Epoch 264/617\n",
      "2562/2562 [==============================] - 0s 136us/sample - loss: 0.7614 - mse: 8.0254 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 265/617\n",
      "2562/2562 [==============================] - 0s 126us/sample - loss: 0.7227 - mse: 6.2863 - val_loss: 0.4562 - val_mse: 1.1514\n",
      "Epoch 266/617\n",
      "2562/2562 [==============================] - 0s 132us/sample - loss: 0.8525 - mse: 29.1813 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 267/617\n",
      "2562/2562 [==============================] - 0s 138us/sample - loss: 0.6599 - mse: 6.7691 - val_loss: 0.4563 - val_mse: 1.1512\n",
      "Epoch 268/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 0.7610 - mse: 9.5318 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 269/617\n",
      "2562/2562 [==============================] - 0s 130us/sample - loss: 0.8031 - mse: 12.4614 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 270/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 0.6876 - mse: 6.0845 - val_loss: 0.4562 - val_mse: 1.1514\n",
      "Epoch 271/617\n",
      "2562/2562 [==============================] - 0s 132us/sample - loss: 0.7474 - mse: 9.7502 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 272/617\n",
      "2562/2562 [==============================] - 0s 129us/sample - loss: 0.6529 - mse: 5.0638 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 273/617\n",
      "2562/2562 [==============================] - 0s 128us/sample - loss: 0.6476 - mse: 5.1055 - val_loss: 0.4559 - val_mse: 1.1522\n",
      "Epoch 274/617\n",
      "2562/2562 [==============================] - 0s 128us/sample - loss: 0.7443 - mse: 6.7903 - val_loss: 0.4558 - val_mse: 1.1529\n",
      "Epoch 275/617\n",
      "2562/2562 [==============================] - 0s 129us/sample - loss: 0.7931 - mse: 36.7811 - val_loss: 0.4559 - val_mse: 1.1525\n",
      "Epoch 276/617\n",
      "2562/2562 [==============================] - 0s 130us/sample - loss: 0.7209 - mse: 7.8412 - val_loss: 0.4559 - val_mse: 1.1524\n",
      "Epoch 277/617\n",
      "2562/2562 [==============================] - 0s 126us/sample - loss: 0.8785 - mse: 24.4017 - val_loss: 0.4559 - val_mse: 1.1525\n",
      "Epoch 278/617\n",
      "2562/2562 [==============================] - 0s 136us/sample - loss: 0.6926 - mse: 10.7791 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 279/617\n",
      "2562/2562 [==============================] - 0s 135us/sample - loss: 0.6767 - mse: 7.3306 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 280/617\n",
      "2562/2562 [==============================] - 0s 120us/sample - loss: 0.6933 - mse: 5.7525 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 281/617\n",
      "2562/2562 [==============================] - 0s 132us/sample - loss: 0.8122 - mse: 14.3802 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 282/617\n",
      "2562/2562 [==============================] - 0s 127us/sample - loss: 0.7600 - mse: 11.5273 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 283/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 0.6613 - mse: 5.9435 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 284/617\n",
      "2562/2562 [==============================] - 0s 125us/sample - loss: 0.9463 - mse: 50.0810 - val_loss: 0.4559 - val_mse: 1.1521\n",
      "Epoch 285/617\n",
      "2562/2562 [==============================] - 0s 126us/sample - loss: 0.6975 - mse: 7.1674 - val_loss: 0.4559 - val_mse: 1.1525\n",
      "Epoch 286/617\n",
      "2562/2562 [==============================] - 0s 128us/sample - loss: 0.8492 - mse: 112.4621 - val_loss: 0.4559 - val_mse: 1.1526\n",
      "Epoch 287/617\n",
      "2562/2562 [==============================] - 0s 132us/sample - loss: 0.6580 - mse: 6.2299 - val_loss: 0.4559 - val_mse: 1.1524\n",
      "Epoch 288/617\n",
      "2562/2562 [==============================] - 0s 128us/sample - loss: 1.4161 - mse: 998.4798 - val_loss: 0.4559 - val_mse: 1.1521\n",
      "Epoch 289/617\n",
      "2562/2562 [==============================] - 0s 123us/sample - loss: 0.7632 - mse: 45.3061 - val_loss: 0.4559 - val_mse: 1.1525\n",
      "Epoch 290/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 0.6961 - mse: 18.4604 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 291/617\n",
      "2562/2562 [==============================] - 0s 128us/sample - loss: 0.7886 - mse: 19.4830 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 292/617\n",
      "2562/2562 [==============================] - 0s 126us/sample - loss: 0.6606 - mse: 10.5104 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 293/617\n",
      "2562/2562 [==============================] - 0s 132us/sample - loss: 0.7083 - mse: 10.6228 - val_loss: 0.4562 - val_mse: 1.1514\n",
      "Epoch 294/617\n",
      "2562/2562 [==============================] - 0s 136us/sample - loss: 0.5662 - mse: 3.2912 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 295/617\n",
      "2562/2562 [==============================] - 0s 120us/sample - loss: 0.6975 - mse: 9.2111 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 296/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 1.3823 - mse: 1376.2600 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 297/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 0.5694 - mse: 2.7328 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 298/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 0.6157 - mse: 5.1443 - val_loss: 0.4564 - val_mse: 1.1509\n",
      "Epoch 299/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 0.6064 - mse: 6.1851 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 300/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 0.6782 - mse: 5.8522 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 301/617\n",
      "2562/2562 [==============================] - 0s 123us/sample - loss: 0.5868 - mse: 3.4125 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 302/617\n",
      "2562/2562 [==============================] - 0s 129us/sample - loss: 0.6190 - mse: 4.9393 - val_loss: 0.4558 - val_mse: 1.1526\n",
      "Epoch 303/617\n",
      "2562/2562 [==============================] - 0s 123us/sample - loss: 0.6090 - mse: 4.4231 - val_loss: 0.4558 - val_mse: 1.1528\n",
      "Epoch 304/617\n",
      "2562/2562 [==============================] - 0s 116us/sample - loss: 0.5794 - mse: 3.4277 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 305/617\n",
      "2562/2562 [==============================] - 0s 127us/sample - loss: 0.6621 - mse: 5.6280 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 306/617\n",
      "2562/2562 [==============================] - 0s 134us/sample - loss: 0.6888 - mse: 8.9333 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 307/617\n",
      "2562/2562 [==============================] - 0s 125us/sample - loss: 0.6691 - mse: 9.7585 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 308/617\n",
      "2562/2562 [==============================] - 0s 116us/sample - loss: 0.6705 - mse: 12.0549 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 309/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 0.6446 - mse: 5.7584 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 310/617\n",
      "2562/2562 [==============================] - 0s 133us/sample - loss: 1.3118 - mse: 1230.2877 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 311/617\n",
      "2562/2562 [==============================] - 0s 133us/sample - loss: 0.5909 - mse: 4.9425 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 312/617\n",
      "2562/2562 [==============================] - 0s 137us/sample - loss: 0.6191 - mse: 5.1101 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 313/617\n",
      "2562/2562 [==============================] - 0s 130us/sample - loss: 0.6557 - mse: 7.3940 - val_loss: 0.4559 - val_mse: 1.1524\n",
      "Epoch 314/617\n",
      "2562/2562 [==============================] - 0s 125us/sample - loss: 0.6418 - mse: 4.6264 - val_loss: 0.4557 - val_mse: 1.1536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/617\n",
      "2562/2562 [==============================] - 0s 135us/sample - loss: 0.6164 - mse: 5.7390 - val_loss: 0.4557 - val_mse: 1.1547\n",
      "Epoch 316/617\n",
      "2562/2562 [==============================] - 0s 128us/sample - loss: 0.6057 - mse: 9.4119 - val_loss: 0.4557 - val_mse: 1.1543\n",
      "Epoch 317/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 0.6192 - mse: 6.7728 - val_loss: 0.4557 - val_mse: 1.1536\n",
      "Epoch 318/617\n",
      "2562/2562 [==============================] - 0s 125us/sample - loss: 0.6376 - mse: 8.7103 - val_loss: 0.4558 - val_mse: 1.1531\n",
      "Epoch 319/617\n",
      "2562/2562 [==============================] - 0s 129us/sample - loss: 0.5316 - mse: 2.2216 - val_loss: 0.4558 - val_mse: 1.1529\n",
      "Epoch 320/617\n",
      "2562/2562 [==============================] - 0s 129us/sample - loss: 0.6338 - mse: 12.0881 - val_loss: 0.4558 - val_mse: 1.1531\n",
      "Epoch 321/617\n",
      "2562/2562 [==============================] - 0s 136us/sample - loss: 0.6043 - mse: 5.3267 - val_loss: 0.4558 - val_mse: 1.1529\n",
      "Epoch 322/617\n",
      "2562/2562 [==============================] - 0s 123us/sample - loss: 0.6240 - mse: 7.7418 - val_loss: 0.4558 - val_mse: 1.1531\n",
      "Epoch 323/617\n",
      "2562/2562 [==============================] - 0s 126us/sample - loss: 0.5447 - mse: 2.4346 - val_loss: 0.4558 - val_mse: 1.1526\n",
      "Epoch 324/617\n",
      "2562/2562 [==============================] - 0s 136us/sample - loss: 0.5788 - mse: 5.2307 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 325/617\n",
      "2562/2562 [==============================] - 0s 136us/sample - loss: 0.5536 - mse: 3.6709 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 326/617\n",
      "2562/2562 [==============================] - 0s 121us/sample - loss: 0.5973 - mse: 4.9602 - val_loss: 0.4563 - val_mse: 1.1512\n",
      "Epoch 327/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 0.6229 - mse: 18.3933 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 328/617\n",
      "2562/2562 [==============================] - 0s 120us/sample - loss: 0.5330 - mse: 2.2348 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 329/617\n",
      "2562/2562 [==============================] - 0s 119us/sample - loss: 0.5096 - mse: 1.7041 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 330/617\n",
      "2562/2562 [==============================] - 0s 118us/sample - loss: 0.6313 - mse: 6.7796 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 331/617\n",
      "2562/2562 [==============================] - 0s 121us/sample - loss: 0.5795 - mse: 4.4156 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 332/617\n",
      "2562/2562 [==============================] - 0s 113us/sample - loss: 0.6009 - mse: 5.2709 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 333/617\n",
      "2562/2562 [==============================] - 0s 120us/sample - loss: 0.5578 - mse: 3.7312 - val_loss: 0.4559 - val_mse: 1.1522\n",
      "Epoch 334/617\n",
      "2562/2562 [==============================] - 0s 115us/sample - loss: 0.5364 - mse: 2.3704 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 335/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 0.5619 - mse: 2.8466 - val_loss: 0.4559 - val_mse: 1.1522\n",
      "Epoch 336/617\n",
      "2562/2562 [==============================] - 0s 120us/sample - loss: 0.5627 - mse: 3.5493 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 337/617\n",
      "2562/2562 [==============================] - 0s 112us/sample - loss: 0.5519 - mse: 3.4550 - val_loss: 0.4565 - val_mse: 1.1508\n",
      "Epoch 338/617\n",
      "2562/2562 [==============================] - 0s 122us/sample - loss: 0.5946 - mse: 3.2179 - val_loss: 0.4565 - val_mse: 1.1508\n",
      "Epoch 339/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.5361 - mse: 2.2759 - val_loss: 0.4564 - val_mse: 1.1509\n",
      "Epoch 340/617\n",
      "2562/2562 [==============================] - 0s 115us/sample - loss: 0.5145 - mse: 1.9860 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 341/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 0.5984 - mse: 7.9659 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 342/617\n",
      "2562/2562 [==============================] - 0s 115us/sample - loss: 0.5339 - mse: 2.8254 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 343/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.7454 - mse: 33.4377 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 344/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.6569 - mse: 7.6709 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 345/617\n",
      "2562/2562 [==============================] - 0s 112us/sample - loss: 0.6731 - mse: 15.4424 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 346/617\n",
      "2562/2562 [==============================] - 0s 113us/sample - loss: 0.5410 - mse: 2.9006 - val_loss: 0.4565 - val_mse: 1.1508\n",
      "Epoch 347/617\n",
      "2562/2562 [==============================] - 0s 115us/sample - loss: 0.5703 - mse: 6.2719 - val_loss: 0.4565 - val_mse: 1.1507\n",
      "Epoch 348/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 0.6607 - mse: 11.8469 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 349/617\n",
      "2562/2562 [==============================] - 0s 114us/sample - loss: 0.5566 - mse: 4.9100 - val_loss: 0.4558 - val_mse: 1.1528\n",
      "Epoch 350/617\n",
      "2562/2562 [==============================] - 0s 115us/sample - loss: 0.5376 - mse: 2.1307 - val_loss: 0.4558 - val_mse: 1.1533\n",
      "Epoch 351/617\n",
      "2562/2562 [==============================] - 0s 112us/sample - loss: 0.6555 - mse: 8.9643 - val_loss: 0.4557 - val_mse: 1.1535\n",
      "Epoch 352/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 0.6170 - mse: 7.5535 - val_loss: 0.4558 - val_mse: 1.1529\n",
      "Epoch 353/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 0.5532 - mse: 3.4377 - val_loss: 0.4561 - val_mse: 1.1517\n",
      "Epoch 354/617\n",
      "2562/2562 [==============================] - 0s 121us/sample - loss: 0.6681 - mse: 56.5456 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 355/617\n",
      "2562/2562 [==============================] - 0s 107us/sample - loss: 0.6153 - mse: 21.5869 - val_loss: 0.4565 - val_mse: 1.1508\n",
      "Epoch 356/617\n",
      "2562/2562 [==============================] - 0s 118us/sample - loss: 0.5176 - mse: 2.4269 - val_loss: 0.4565 - val_mse: 1.1507\n",
      "Epoch 357/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 0.5526 - mse: 5.4311 - val_loss: 0.4564 - val_mse: 1.1510\n",
      "Epoch 358/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.5575 - mse: 3.3727 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 359/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 0.5397 - mse: 1.9753 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 360/617\n",
      "2562/2562 [==============================] - 0s 120us/sample - loss: 0.5375 - mse: 2.6369 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 361/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 0.5934 - mse: 9.7695 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 362/617\n",
      "2562/2562 [==============================] - 0s 123us/sample - loss: 0.5203 - mse: 2.5258 - val_loss: 0.4559 - val_mse: 1.1524\n",
      "Epoch 363/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.5398 - mse: 2.3983 - val_loss: 0.4558 - val_mse: 1.1526\n",
      "Epoch 364/617\n",
      "2562/2562 [==============================] - 0s 113us/sample - loss: 0.5103 - mse: 2.2495 - val_loss: 0.4558 - val_mse: 1.1526\n",
      "Epoch 365/617\n",
      "2562/2562 [==============================] - 0s 107us/sample - loss: 0.5539 - mse: 3.5954 - val_loss: 0.4559 - val_mse: 1.1525\n",
      "Epoch 366/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.5639 - mse: 4.0176 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 367/617\n",
      "2562/2562 [==============================] - 0s 114us/sample - loss: 0.6037 - mse: 6.3320 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 368/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 0.5430 - mse: 3.1092 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 369/617\n",
      "2562/2562 [==============================] - 0s 113us/sample - loss: 0.5512 - mse: 3.3689 - val_loss: 0.4564 - val_mse: 1.1509\n",
      "Epoch 370/617\n",
      "2562/2562 [==============================] - 0s 112us/sample - loss: 0.6500 - mse: 16.6851 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 371/617\n",
      "2562/2562 [==============================] - 0s 112us/sample - loss: 0.5479 - mse: 5.2299 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 372/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.5330 - mse: 3.6219 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 373/617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2562/2562 [==============================] - 0s 108us/sample - loss: 0.5425 - mse: 3.8075 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 374/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 0.5168 - mse: 2.0250 - val_loss: 0.4564 - val_mse: 1.1509\n",
      "Epoch 375/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 0.5341 - mse: 2.6709 - val_loss: 0.4568 - val_mse: 1.1505\n",
      "Epoch 376/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 0.5544 - mse: 3.1562 - val_loss: 0.4567 - val_mse: 1.1506\n",
      "Epoch 377/617\n",
      "2562/2562 [==============================] - 0s 141us/sample - loss: 0.5736 - mse: 4.2846 - val_loss: 0.4567 - val_mse: 1.1505\n",
      "Epoch 378/617\n",
      "2562/2562 [==============================] - 0s 108us/sample - loss: 0.5884 - mse: 7.6043 - val_loss: 0.4567 - val_mse: 1.1505\n",
      "Epoch 379/617\n",
      "2562/2562 [==============================] - 0s 104us/sample - loss: 0.5176 - mse: 1.9206 - val_loss: 0.4565 - val_mse: 1.1507\n",
      "Epoch 380/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.5493 - mse: 3.7854 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 381/617\n",
      "2562/2562 [==============================] - 0s 108us/sample - loss: 0.5662 - mse: 3.1360 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 382/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.6358 - mse: 13.3664 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 383/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 0.5615 - mse: 6.7086 - val_loss: 0.4558 - val_mse: 1.1528\n",
      "Epoch 384/617\n",
      "2562/2562 [==============================] - 0s 108us/sample - loss: 0.5564 - mse: 4.7399 - val_loss: 0.4558 - val_mse: 1.1527\n",
      "Epoch 385/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 0.6667 - mse: 22.5044 - val_loss: 0.4558 - val_mse: 1.1527\n",
      "Epoch 386/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 0.5660 - mse: 3.6244 - val_loss: 0.4558 - val_mse: 1.1527\n",
      "Epoch 387/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 0.5215 - mse: 3.3449 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 388/617\n",
      "2562/2562 [==============================] - 0s 131us/sample - loss: 0.6345 - mse: 44.8195 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 389/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 0.5209 - mse: 2.4477 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 390/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.6298 - mse: 28.1685 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 391/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.5041 - mse: 1.8999 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 392/617\n",
      "2562/2562 [==============================] - 0s 112us/sample - loss: 0.6827 - mse: 34.3028 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 393/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.5019 - mse: 1.8114 - val_loss: 0.4566 - val_mse: 1.1507\n",
      "Epoch 394/617\n",
      "2562/2562 [==============================] - 0s 119us/sample - loss: 0.5047 - mse: 2.0242 - val_loss: 0.4569 - val_mse: 1.1504\n",
      "Epoch 395/617\n",
      "2562/2562 [==============================] - 0s 128us/sample - loss: 0.5124 - mse: 2.2273 - val_loss: 0.4567 - val_mse: 1.1505\n",
      "Epoch 396/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.5402 - mse: 2.7184 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 397/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.5494 - mse: 4.2469 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 398/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.7162 - mse: 42.5203 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 399/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.5141 - mse: 2.0694 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 400/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.5380 - mse: 3.1079 - val_loss: 0.4565 - val_mse: 1.1507\n",
      "Epoch 401/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5304 - mse: 4.1026 - val_loss: 0.4566 - val_mse: 1.1507\n",
      "Epoch 402/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.8792 - mse: 367.8034 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 403/617\n",
      "2562/2562 [==============================] - 0s 104us/sample - loss: 0.5155 - mse: 2.1247 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 404/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5473 - mse: 3.3756 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 405/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.4972 - mse: 2.0086 - val_loss: 0.4564 - val_mse: 1.1508\n",
      "Epoch 406/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.4871 - mse: 1.6514 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 407/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.5056 - mse: 1.8136 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 408/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.5040 - mse: 2.0871 - val_loss: 0.4559 - val_mse: 1.1524\n",
      "Epoch 409/617\n",
      "2562/2562 [==============================] - 0s 108us/sample - loss: 0.5283 - mse: 2.6583 - val_loss: 0.4558 - val_mse: 1.1530\n",
      "Epoch 410/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.6164 - mse: 8.7952 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 411/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.5377 - mse: 3.4464 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 412/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.5212 - mse: 2.0549 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 413/617\n",
      "2562/2562 [==============================] - 0s 104us/sample - loss: 0.4935 - mse: 1.8631 - val_loss: 0.4559 - val_mse: 1.1521\n",
      "Epoch 414/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.6000 - mse: 10.4700 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 415/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.5201 - mse: 2.2204 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 416/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5515 - mse: 4.3505 - val_loss: 0.4564 - val_mse: 1.1509\n",
      "Epoch 417/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4878 - mse: 1.8524 - val_loss: 0.4566 - val_mse: 1.1507\n",
      "Epoch 418/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.5144 - mse: 2.4746 - val_loss: 0.4564 - val_mse: 1.1508\n",
      "Epoch 419/617\n",
      "2562/2562 [==============================] - 0s 97us/sample - loss: 0.5679 - mse: 6.9605 - val_loss: 0.4566 - val_mse: 1.1507\n",
      "Epoch 420/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5053 - mse: 2.1458 - val_loss: 0.4567 - val_mse: 1.1506\n",
      "Epoch 421/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.4964 - mse: 2.0735 - val_loss: 0.4567 - val_mse: 1.1505\n",
      "Epoch 422/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.4974 - mse: 1.9115 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 423/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.4909 - mse: 1.5542 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 424/617\n",
      "2562/2562 [==============================] - 0s 104us/sample - loss: 0.6026 - mse: 12.0129 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 425/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.4898 - mse: 1.5645 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 426/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.4951 - mse: 1.6839 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 427/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 0.5339 - mse: 4.2054 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 428/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.5262 - mse: 2.4752 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 429/617\n",
      "2562/2562 [==============================] - 0s 108us/sample - loss: 0.5335 - mse: 2.7461 - val_loss: 0.4564 - val_mse: 1.1509\n",
      "Epoch 430/617\n",
      "2562/2562 [==============================] - 0s 121us/sample - loss: 0.4886 - mse: 1.6228 - val_loss: 0.4565 - val_mse: 1.1508\n",
      "Epoch 431/617\n",
      "2562/2562 [==============================] - 0s 116us/sample - loss: 0.5069 - mse: 2.9053 - val_loss: 0.4565 - val_mse: 1.1507\n",
      "Epoch 432/617\n",
      "2562/2562 [==============================] - 0s 108us/sample - loss: 0.6319 - mse: 34.8298 - val_loss: 0.4566 - val_mse: 1.1506\n",
      "Epoch 433/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.5133 - mse: 2.1636 - val_loss: 0.4566 - val_mse: 1.1506\n",
      "Epoch 434/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.5271 - mse: 2.8980 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 435/617\n",
      "2562/2562 [==============================] - 0s 108us/sample - loss: 0.5037 - mse: 2.0541 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 436/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4937 - mse: 1.9664 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 437/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.4964 - mse: 2.0196 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 438/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.5337 - mse: 7.0692 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 439/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.5497 - mse: 4.8126 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 440/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 0.5071 - mse: 3.0132 - val_loss: 0.4558 - val_mse: 1.1530\n",
      "Epoch 441/617\n",
      "2562/2562 [==============================] - 0s 107us/sample - loss: 0.4740 - mse: 1.3719 - val_loss: 0.4558 - val_mse: 1.1532\n",
      "Epoch 442/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.5584 - mse: 4.2130 - val_loss: 0.4558 - val_mse: 1.1531\n",
      "Epoch 443/617\n",
      "2562/2562 [==============================] - 0s 104us/sample - loss: 0.5347 - mse: 3.3578 - val_loss: 0.4559 - val_mse: 1.1525\n",
      "Epoch 444/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.5044 - mse: 1.7577 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 445/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.4898 - mse: 1.7510 - val_loss: 0.4564 - val_mse: 1.1510\n",
      "Epoch 446/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.5188 - mse: 2.8913 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 447/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.4986 - mse: 1.7533 - val_loss: 0.4565 - val_mse: 1.1508\n",
      "Epoch 448/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.5063 - mse: 2.2625 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 449/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5516 - mse: 6.7124 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 450/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.5427 - mse: 4.1189 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 451/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5070 - mse: 1.9916 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 452/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.5146 - mse: 2.7801 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 453/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.6155 - mse: 20.4492 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 454/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5005 - mse: 2.6846 - val_loss: 0.4564 - val_mse: 1.1510\n",
      "Epoch 455/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.5538 - mse: 3.8625 - val_loss: 0.4566 - val_mse: 1.1506\n",
      "Epoch 456/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.4996 - mse: 2.0910 - val_loss: 0.4567 - val_mse: 1.1506\n",
      "Epoch 457/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.4891 - mse: 1.7571 - val_loss: 0.4567 - val_mse: 1.1505\n",
      "Epoch 458/617\n",
      "2562/2562 [==============================] - 0s 107us/sample - loss: 0.5959 - mse: 19.3133 - val_loss: 0.4565 - val_mse: 1.1508\n",
      "Epoch 459/617\n",
      "2562/2562 [==============================] - 0s 96us/sample - loss: 0.5030 - mse: 2.4976 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 460/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5110 - mse: 3.1981 - val_loss: 0.4562 - val_mse: 1.1514\n",
      "Epoch 461/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.4989 - mse: 1.8341 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 462/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 0.4864 - mse: 1.4448 - val_loss: 0.4559 - val_mse: 1.1521\n",
      "Epoch 463/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5580 - mse: 9.2102 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 464/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.4780 - mse: 1.7321 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 465/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.5125 - mse: 3.0307 - val_loss: 0.4565 - val_mse: 1.1508\n",
      "Epoch 466/617\n",
      "2562/2562 [==============================] - 0s 124us/sample - loss: 0.5963 - mse: 6.9941 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 467/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.4759 - mse: 1.3393 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 468/617\n",
      "2562/2562 [==============================] - 0s 111us/sample - loss: 0.5418 - mse: 4.2402 - val_loss: 0.4564 - val_mse: 1.1509\n",
      "Epoch 469/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.5460 - mse: 3.4409 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 470/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.5316 - mse: 3.7184 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 471/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.5305 - mse: 3.9867 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 472/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.4829 - mse: 1.7539 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 473/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.4839 - mse: 1.4824 - val_loss: 0.4565 - val_mse: 1.1507\n",
      "Epoch 474/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4712 - mse: 1.3817 - val_loss: 0.4566 - val_mse: 1.1506\n",
      "Epoch 475/617\n",
      "2562/2562 [==============================] - 0s 107us/sample - loss: 0.5076 - mse: 2.8472 - val_loss: 0.4565 - val_mse: 1.1508\n",
      "Epoch 476/617\n",
      "2562/2562 [==============================] - 0s 97us/sample - loss: 0.5031 - mse: 3.2765 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 477/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 0.5264 - mse: 2.9146 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 478/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.4878 - mse: 1.5203 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 479/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.5008 - mse: 2.1178 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 480/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.5145 - mse: 2.2532 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 481/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.5025 - mse: 2.4235 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 482/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.4944 - mse: 2.1946 - val_loss: 0.4558 - val_mse: 1.1525\n",
      "Epoch 483/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.4973 - mse: 2.1120 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 484/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.5816 - mse: 23.3956 - val_loss: 0.4559 - val_mse: 1.1521\n",
      "Epoch 485/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.5389 - mse: 6.5306 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 486/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4746 - mse: 1.4654 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 487/617\n",
      "2562/2562 [==============================] - 0s 104us/sample - loss: 0.5024 - mse: 2.2498 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 488/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5483 - mse: 7.3391 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 489/617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2562/2562 [==============================] - 0s 111us/sample - loss: 0.5013 - mse: 2.6797 - val_loss: 0.4559 - val_mse: 1.1521\n",
      "Epoch 490/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.5438 - mse: 4.7439 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 491/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.5358 - mse: 4.1205 - val_loss: 0.4561 - val_mse: 1.1517\n",
      "Epoch 492/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5006 - mse: 2.2425 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 493/617\n",
      "2562/2562 [==============================] - 0s 96us/sample - loss: 0.4819 - mse: 1.7928 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 494/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5311 - mse: 3.8641 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 495/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.5507 - mse: 5.8406 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 496/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.5109 - mse: 2.3357 - val_loss: 0.4559 - val_mse: 1.1522\n",
      "Epoch 497/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4760 - mse: 1.2995 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 498/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.5362 - mse: 5.3201 - val_loss: 0.4558 - val_mse: 1.1526\n",
      "Epoch 499/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.4990 - mse: 1.7659 - val_loss: 0.4558 - val_mse: 1.1529\n",
      "Epoch 500/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.5248 - mse: 3.1263 - val_loss: 0.4558 - val_mse: 1.1526\n",
      "Epoch 501/617\n",
      "2562/2562 [==============================] - 0s 126us/sample - loss: 0.5474 - mse: 4.0009 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 502/617\n",
      "2562/2562 [==============================] - 0s 108us/sample - loss: 0.5610 - mse: 6.6174 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 503/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.4860 - mse: 1.6340 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 504/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.5464 - mse: 6.6927 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 505/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.5159 - mse: 2.1245 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 506/617\n",
      "2562/2562 [==============================] - 0s 96us/sample - loss: 0.5040 - mse: 1.7582 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 507/617\n",
      "2562/2562 [==============================] - 0s 93us/sample - loss: 0.5253 - mse: 5.3005 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 508/617\n",
      "2562/2562 [==============================] - 0s 94us/sample - loss: 0.4759 - mse: 1.4554 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 509/617\n",
      "2562/2562 [==============================] - 0s 94us/sample - loss: 0.4669 - mse: 1.3038 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 510/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.5191 - mse: 2.4706 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 511/617\n",
      "2562/2562 [==============================] - 0s 93us/sample - loss: 0.5697 - mse: 17.7488 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 512/617\n",
      "2562/2562 [==============================] - 0s 94us/sample - loss: 0.5273 - mse: 4.4183 - val_loss: 0.4559 - val_mse: 1.1522\n",
      "Epoch 513/617\n",
      "2562/2562 [==============================] - 0s 92us/sample - loss: 0.4690 - mse: 1.3528 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 514/617\n",
      "2562/2562 [==============================] - 0s 96us/sample - loss: 0.5008 - mse: 1.8034 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 515/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.4989 - mse: 2.2575 - val_loss: 0.4564 - val_mse: 1.1509\n",
      "Epoch 516/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.4830 - mse: 1.6658 - val_loss: 0.4565 - val_mse: 1.1507\n",
      "Epoch 517/617\n",
      "2562/2562 [==============================] - 0s 93us/sample - loss: 0.4772 - mse: 1.5716 - val_loss: 0.4566 - val_mse: 1.1507\n",
      "Epoch 518/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.4950 - mse: 1.8715 - val_loss: 0.4567 - val_mse: 1.1506\n",
      "Epoch 519/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.4779 - mse: 1.4609 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 520/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.4799 - mse: 1.6773 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 521/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.4778 - mse: 1.6358 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 522/617\n",
      "2562/2562 [==============================] - 0s 92us/sample - loss: 0.4794 - mse: 1.4005 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 523/617\n",
      "2562/2562 [==============================] - 0s 94us/sample - loss: 0.4801 - mse: 1.5474 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 524/617\n",
      "2562/2562 [==============================] - 0s 92us/sample - loss: 0.4925 - mse: 1.8983 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 525/617\n",
      "2562/2562 [==============================] - 0s 92us/sample - loss: 0.4963 - mse: 2.6950 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 526/617\n",
      "2562/2562 [==============================] - 0s 93us/sample - loss: 0.5035 - mse: 2.7790 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 527/617\n",
      "2562/2562 [==============================] - 0s 96us/sample - loss: 0.4773 - mse: 1.8621 - val_loss: 0.4561 - val_mse: 1.1517\n",
      "Epoch 528/617\n",
      "2562/2562 [==============================] - 0s 90us/sample - loss: 0.4832 - mse: 1.4797 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 529/617\n",
      "2562/2562 [==============================] - 0s 93us/sample - loss: 0.5149 - mse: 3.0871 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 530/617\n",
      "2562/2562 [==============================] - 0s 93us/sample - loss: 0.5212 - mse: 5.5794 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 531/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4981 - mse: 2.3244 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 532/617\n",
      "2562/2562 [==============================] - 0s 93us/sample - loss: 0.5136 - mse: 1.9240 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 533/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4883 - mse: 2.3193 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 534/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.5456 - mse: 4.3936 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 535/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.5490 - mse: 3.9136 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 536/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.5030 - mse: 4.8440 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 537/617\n",
      "2562/2562 [==============================] - 0s 96us/sample - loss: 0.4476 - mse: 1.1408 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 538/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.5114 - mse: 3.4140 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 539/617\n",
      "2562/2562 [==============================] - 0s 97us/sample - loss: 0.4700 - mse: 1.4385 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 540/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.4841 - mse: 1.7329 - val_loss: 0.4559 - val_mse: 1.1525\n",
      "Epoch 541/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.5073 - mse: 2.7055 - val_loss: 0.4558 - val_mse: 1.1533\n",
      "Epoch 542/617\n",
      "2562/2562 [==============================] - ETA: 0s - loss: 0.5144 - mse: 3.380 - 1s 240us/sample - loss: 0.5131 - mse: 3.3273 - val_loss: 0.4558 - val_mse: 1.1528\n",
      "Epoch 543/617\n",
      "2562/2562 [==============================] - 0s 147us/sample - loss: 0.5241 - mse: 3.2543 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 544/617\n",
      "2562/2562 [==============================] - 0s 105us/sample - loss: 0.5039 - mse: 2.2014 - val_loss: 0.4562 - val_mse: 1.1514\n",
      "Epoch 545/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.4802 - mse: 1.6032 - val_loss: 0.4559 - val_mse: 1.1521\n",
      "Epoch 546/617\n",
      "2562/2562 [==============================] - 0s 104us/sample - loss: 0.6775 - mse: 62.0320 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 547/617\n",
      "2562/2562 [==============================] - 0s 117us/sample - loss: 0.4785 - mse: 1.3561 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 548/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.4771 - mse: 1.4632 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 549/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.4781 - mse: 1.5287 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 550/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.5188 - mse: 3.3482 - val_loss: 0.4566 - val_mse: 1.1507\n",
      "Epoch 551/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.4742 - mse: 1.3994 - val_loss: 0.4569 - val_mse: 1.1504\n",
      "Epoch 552/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.6081 - mse: 54.2727 - val_loss: 0.4572 - val_mse: 1.1503\n",
      "Epoch 553/617\n",
      "2562/2562 [==============================] - 0s 90us/sample - loss: 0.4726 - mse: 1.5394 - val_loss: 0.4568 - val_mse: 1.1505\n",
      "Epoch 554/617\n",
      "2562/2562 [==============================] - 0s 90us/sample - loss: 0.5222 - mse: 8.0186 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 555/617\n",
      "2562/2562 [==============================] - 0s 93us/sample - loss: 0.5162 - mse: 3.2782 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 556/617\n",
      "2562/2562 [==============================] - 0s 92us/sample - loss: 0.4717 - mse: 1.8778 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 557/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.5259 - mse: 4.0496 - val_loss: 0.4561 - val_mse: 1.1514\n",
      "Epoch 558/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.4799 - mse: 2.0595 - val_loss: 0.4562 - val_mse: 1.1514\n",
      "Epoch 559/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.4922 - mse: 2.3888 - val_loss: 0.4561 - val_mse: 1.1516\n",
      "Epoch 560/617\n",
      "2562/2562 [==============================] - 0s 94us/sample - loss: 0.4925 - mse: 3.0957 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 561/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.4678 - mse: 1.2994 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 562/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.4817 - mse: 1.5577 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 563/617\n",
      "2562/2562 [==============================] - 0s 94us/sample - loss: 0.4925 - mse: 2.4867 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 564/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.4875 - mse: 1.9513 - val_loss: 0.4559 - val_mse: 1.1522\n",
      "Epoch 565/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4837 - mse: 2.0441 - val_loss: 0.4560 - val_mse: 1.1519\n",
      "Epoch 566/617\n",
      "2562/2562 [==============================] - 0s 94us/sample - loss: 0.5036 - mse: 4.5215 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 567/617\n",
      "2562/2562 [==============================] - 0s 97us/sample - loss: 0.4827 - mse: 1.4440 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 568/617\n",
      "2562/2562 [==============================] - 0s 91us/sample - loss: 0.4765 - mse: 1.8852 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 569/617\n",
      "2562/2562 [==============================] - 0s 94us/sample - loss: 0.4547 - mse: 1.1685 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 570/617\n",
      "2562/2562 [==============================] - 0s 92us/sample - loss: 0.5803 - mse: 26.4831 - val_loss: 0.4564 - val_mse: 1.1508\n",
      "Epoch 571/617\n",
      "2562/2562 [==============================] - 0s 96us/sample - loss: 0.4698 - mse: 1.4268 - val_loss: 0.4565 - val_mse: 1.1507\n",
      "Epoch 572/617\n",
      "2562/2562 [==============================] - 0s 95us/sample - loss: 0.4682 - mse: 1.6514 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 573/617\n",
      "2562/2562 [==============================] - 0s 97us/sample - loss: 0.4958 - mse: 2.7827 - val_loss: 0.4561 - val_mse: 1.1517\n",
      "Epoch 574/617\n",
      "2562/2562 [==============================] - 0s 117us/sample - loss: 0.5544 - mse: 12.4520 - val_loss: 0.4559 - val_mse: 1.1521\n",
      "Epoch 575/617\n",
      "2562/2562 [==============================] - 0s 137us/sample - loss: 0.4768 - mse: 1.4715 - val_loss: 0.4559 - val_mse: 1.1524\n",
      "Epoch 576/617\n",
      "2562/2562 [==============================] - 0s 117us/sample - loss: 0.4943 - mse: 2.4369 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 577/617\n",
      "2562/2562 [==============================] - 0s 117us/sample - loss: 0.4723 - mse: 1.5294 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 578/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 0.4612 - mse: 1.2920 - val_loss: 0.4559 - val_mse: 1.1524\n",
      "Epoch 579/617\n",
      "2562/2562 [==============================] - 0s 107us/sample - loss: 0.4829 - mse: 1.5341 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 580/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 0.4630 - mse: 1.2334 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 581/617\n",
      "2562/2562 [==============================] - 0s 96us/sample - loss: 0.5183 - mse: 9.8050 - val_loss: 0.4562 - val_mse: 1.1514\n",
      "Epoch 582/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.4889 - mse: 1.9919 - val_loss: 0.4562 - val_mse: 1.1514\n",
      "Epoch 583/617\n",
      "2562/2562 [==============================] - 0s 96us/sample - loss: 0.4707 - mse: 1.5359 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 584/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4854 - mse: 2.1233 - val_loss: 0.4559 - val_mse: 1.1521\n",
      "Epoch 585/617\n",
      "2562/2562 [==============================] - 0s 96us/sample - loss: 0.4582 - mse: 1.1819 - val_loss: 0.4559 - val_mse: 1.1523\n",
      "Epoch 586/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4880 - mse: 2.2674 - val_loss: 0.4561 - val_mse: 1.1517\n",
      "Epoch 587/617\n",
      "2562/2562 [==============================] - 0s 109us/sample - loss: 0.5351 - mse: 13.2193 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 588/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 0.4889 - mse: 1.9028 - val_loss: 0.4566 - val_mse: 1.1507\n",
      "Epoch 589/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.4990 - mse: 2.0146 - val_loss: 0.4565 - val_mse: 1.1507\n",
      "Epoch 590/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.4967 - mse: 2.1401 - val_loss: 0.4563 - val_mse: 1.1510\n",
      "Epoch 591/617\n",
      "2562/2562 [==============================] - 0s 112us/sample - loss: 0.5111 - mse: 4.6626 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 592/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.4554 - mse: 1.1896 - val_loss: 0.4559 - val_mse: 1.1521\n",
      "Epoch 593/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 0.4891 - mse: 2.3741 - val_loss: 0.4558 - val_mse: 1.1525\n",
      "Epoch 594/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.4775 - mse: 1.4688 - val_loss: 0.4558 - val_mse: 1.1526\n",
      "Epoch 595/617\n",
      "2562/2562 [==============================] - 0s 115us/sample - loss: 0.4594 - mse: 1.1893 - val_loss: 0.4559 - val_mse: 1.1520\n",
      "Epoch 596/617\n",
      "2562/2562 [==============================] - 0s 108us/sample - loss: 0.5029 - mse: 2.8038 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 597/617\n",
      "2562/2562 [==============================] - 0s 107us/sample - loss: 0.4794 - mse: 1.5512 - val_loss: 0.4565 - val_mse: 1.1508\n",
      "Epoch 598/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.4887 - mse: 2.2589 - val_loss: 0.4566 - val_mse: 1.1507\n",
      "Epoch 599/617\n",
      "2562/2562 [==============================] - 0s 108us/sample - loss: 0.4667 - mse: 1.3796 - val_loss: 0.4567 - val_mse: 1.1506\n",
      "Epoch 600/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.4845 - mse: 1.7940 - val_loss: 0.4566 - val_mse: 1.1507\n",
      "Epoch 601/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.4992 - mse: 3.4956 - val_loss: 0.4564 - val_mse: 1.1509\n",
      "Epoch 602/617\n",
      "2562/2562 [==============================] - 0s 103us/sample - loss: 0.4739 - mse: 1.4214 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 603/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.4798 - mse: 1.6792 - val_loss: 0.4562 - val_mse: 1.1512\n",
      "Epoch 604/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.4706 - mse: 1.7359 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 605/617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4731 - mse: 1.5453 - val_loss: 0.4559 - val_mse: 1.1521\n",
      "Epoch 606/617\n",
      "2562/2562 [==============================] - 0s 100us/sample - loss: 0.5216 - mse: 7.7251 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Epoch 607/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.4705 - mse: 1.4593 - val_loss: 0.4565 - val_mse: 1.1508\n",
      "Epoch 608/617\n",
      "2562/2562 [==============================] - 0s 101us/sample - loss: 0.5573 - mse: 14.6854 - val_loss: 0.4567 - val_mse: 1.1505\n",
      "Epoch 609/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.4773 - mse: 1.5476 - val_loss: 0.4567 - val_mse: 1.1505\n",
      "Epoch 610/617\n",
      "2562/2562 [==============================] - 0s 104us/sample - loss: 0.6574 - mse: 88.4111 - val_loss: 0.4564 - val_mse: 1.1510\n",
      "Epoch 611/617\n",
      "2562/2562 [==============================] - 0s 98us/sample - loss: 0.4683 - mse: 1.5745 - val_loss: 0.4563 - val_mse: 1.1511\n",
      "Epoch 612/617\n",
      "2562/2562 [==============================] - 0s 104us/sample - loss: 0.4585 - mse: 1.2210 - val_loss: 0.4560 - val_mse: 1.1517\n",
      "Epoch 613/617\n",
      "2562/2562 [==============================] - 0s 99us/sample - loss: 0.5057 - mse: 2.4339 - val_loss: 0.4562 - val_mse: 1.1513\n",
      "Epoch 614/617\n",
      "2562/2562 [==============================] - 0s 106us/sample - loss: 0.6243 - mse: 21.2731 - val_loss: 0.4560 - val_mse: 1.1518\n",
      "Epoch 615/617\n",
      "2562/2562 [==============================] - 0s 102us/sample - loss: 0.4696 - mse: 1.4386 - val_loss: 0.4558 - val_mse: 1.1526\n",
      "Epoch 616/617\n",
      "2562/2562 [==============================] - 0s 110us/sample - loss: 0.5383 - mse: 11.6720 - val_loss: 0.4560 - val_mse: 1.1520\n",
      "Epoch 617/617\n",
      "2562/2562 [==============================] - 0s 113us/sample - loss: 0.4715 - mse: 1.4604 - val_loss: 0.4561 - val_mse: 1.1515\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow.keras import layers\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(300, activation='relu', \n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "                 #kernel_regularizer=regularizers.l2(0.001),kernel_initializer='normal',\n",
    "                 input_shape=(FEATURES,)),\n",
    "    layers.Dropout(0.1),\n",
    "        layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "        \n",
    "    #layers.Dense(units, activation=activation_func),\n",
    "    #layers.SimpleRNN(100,unroll=True),\n",
    "    layers.Dense(1,activation='linear')#'relu' ,activation='linear'\n",
    "])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='mse', patience=10)\n",
    "\n",
    "#opt = tf.keras.optimizers.SGD(lr=0.000001, momentum=0.9)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer='adam', metrics=['mse'])\n",
    "print(model.summary())\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=617, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0723805294763609"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(1.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw2_test=pd.read_csv('df_raw2_test.csv') \n",
    "\n",
    "df=df_raw2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_cols = [\"id\",\"imdb_score\"]\n",
    "\n",
    "train_cols = df.columns[~df.columns.isin(useless_cols)]\n",
    "# X_train = df[train_cols]\n",
    "# y_train = df[\"imdb_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_holdout=df[train_cols]\n",
    "y_test_holdout=df[\"imdb_score\"]\n",
    "y_pred_keras = model.predict(X_test_holdout)\n",
    "#y_pred_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP - test rmse:  1.1672249200536071\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import math\n",
    "print('MLP - test rmse: ', math.sqrt(metrics.mean_squared_error(y_test_holdout, y_pred_keras)))\n",
    "# MLP - test rmse:  1.1672249200536071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
